{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f8eb03b",
   "metadata": {},
   "source": [
    "# Preprocessing and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c42ab5",
   "metadata": {},
   "source": [
    "On this notebook is developed the preprocessing and the topic mining process helped by the gensim library, that will be applied to our corpus made by newspaper texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a078a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import math\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6de35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lines(corpus):\n",
    "    all_lines = list()\n",
    "    with open(corpus, 'r', encoding = 'latin-1') as rfile:\n",
    "        for line in rfile:\n",
    "            all_lines.append(line)\n",
    "    \n",
    "    return all_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2bed186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lines_by_words(lines):\n",
    "    new_lines = list()\n",
    "    for line in lines:\n",
    "        new_line = line.lower()\n",
    "        new_lines.append(nltk.word_tokenize(new_line))\n",
    "    \n",
    "    return new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef42cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_alphabetic_text_lines(lines):\n",
    "    new_lines = list()\n",
    "    for line in lines:\n",
    "        new_line = list()\n",
    "        for word in line:\n",
    "            token = list()\n",
    "            for c in word:\n",
    "                #[a-záéíóúñü+$]\n",
    "                if re.match(r'^[a-záéíóúñü+$]', c):\n",
    "                    token.append(c)\n",
    "            token = ''.join(token)\n",
    "            if token != '':\n",
    "                new_line.append(token)\n",
    "        new_lines.append(new_line)\n",
    "        \n",
    "    return new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d68270f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(lines):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    clean_lines = list()\n",
    "    for line in lines:\n",
    "        clean_line = list()\n",
    "        for word in line:\n",
    "            if word not in stopwords:\n",
    "                clean_line.append(word)\n",
    "        clean_lines.append(clean_line)\n",
    "    \n",
    "    return clean_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56efba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(lines):\n",
    "    X = list()\n",
    "    y = list()\n",
    "    for line in lines:\n",
    "        n = len(line)\n",
    "        tag = line.pop(n - 1)\n",
    "        corpus = line\n",
    "        X.append(corpus)\n",
    "        y.append(tag)\n",
    "    return [X, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8061f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_tag(y):\n",
    "    new_y = list()\n",
    "    for i in y:\n",
    "        if i == 'spam':\n",
    "            new_i = 1\n",
    "        else:\n",
    "            new_i = 0\n",
    "        new_y.append(new_i)\n",
    "    return np.array(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3060e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_X(X):\n",
    "    lemmas_X = list()\n",
    "    tags = ['j', 'n', 'r', 'v']\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    for line in X:\n",
    "        tagged_line = nltk.pos_tag(line)\n",
    "        #print(tagged_line)\n",
    "        lemmas_line = list()\n",
    "        for token in tagged_line:\n",
    "            tag = token[1]\n",
    "            if tag in tags:\n",
    "                lemmatized_token = wnl.lemmatize(token, tag)\n",
    "            else:\n",
    "                lemmatized_token = token[0]\n",
    "            lemmas_line.append(lemmatized_token)\n",
    "        lemmas_X.append(lemmas_line)\n",
    "    return lemmas_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f0e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(X):\n",
    "    words = list()\n",
    "    for line in X:\n",
    "        for word in line:\n",
    "            words.append(word)\n",
    "    vocabulary = list(sorted(set(words)))\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02eb6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_X(X, vocabulary):\n",
    "    matrix_X = list()\n",
    "    for line in X:\n",
    "        xi = list()\n",
    "        xi.append(1)\n",
    "        m = len(line)\n",
    "        for word in vocabulary:\n",
    "            if m != 0:\n",
    "                xi.append(line.count(word) / m) \n",
    "            else:\n",
    "                xi.append(m)\n",
    "        xi = np.array(xi)\n",
    "        matrix_X.append(xi)\n",
    "    matrix_X = np.array(matrix_X)\n",
    "    return matrix_X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b200eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateSet(X, Y, test_percentage):\n",
    "    data_zipped = list(zip(X, Y))\n",
    "    random.shuffle(data_zipped) # revuelve la data \n",
    "    X, Y = zip(*data_zipped) # descomprime el iterable dado\n",
    "\n",
    "    total_test = math.ceil(len(Y) * test_percentage)\n",
    "    total_train = len(Y) - total_test\n",
    "\n",
    "    X_train = X[:total_train]\n",
    "    X_test = X[total_train:]\n",
    "    Y_train = Y[:total_train]\n",
    "    Y_test = Y[total_train:]\n",
    "\n",
    "    return np.array(X_train), np.array(Y_train), np.array(X_test), np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b68944bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_w(n):\n",
    "    w = np.zeros(n)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97aa37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z(matrix_X, w):\n",
    "    z = np.dot(matrix_X, w.T)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86a0d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(z):\n",
    "    new_Y = np.exp(z) / (1 + np.exp(z))\n",
    "    return np.array(new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a745089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def j(Y, prediction):\n",
    "    sum1 = np.sum(Y * np.log(prediction))\n",
    "    sum2 = np.sum((1 - Y) * np.log(1 - prediction))\n",
    "    result = - (sum1 + sum2) / len(Y)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eb45025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_partial(matrix_X, Y, prediction):\n",
    "    result = list()\n",
    "    for x in matrix_X.T:\n",
    "        result.append((1 / len(Y)) * np.dot((prediction - Y), x))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25fd1ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_w(w, jpartial, alpha):\n",
    "    #print(w)\n",
    "    new_w =  w - (alpha * jpartial)\n",
    "    #print(jpartial)\n",
    "    #print(new_w)\n",
    "    return new_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "335dbc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(matrix_X, Y, w, alpha, iterations = 1000):\n",
    "    for i in range(iterations):\n",
    "        z = get_z(matrix_X, w)\n",
    "        new_Y = prediction(z)\n",
    "        error = j(Y, new_Y)\n",
    "        new_w = j_partial(matrix_X, Y, new_Y)\n",
    "        w = get_new_w(w, new_w, alpha)\n",
    "        if i % 50 == 0:\n",
    "            print(\"In iteration\", i, \"the cost function is\", error)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d45c97f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(matrix_X, Y, w):\n",
    "    z = get_z(matrix_X, w)\n",
    "    Y_pred = prediction(z)\n",
    "\n",
    "    table = []\n",
    "    correct = 0\n",
    "    for i in range(len(Y)):\n",
    "        #error = abs(100 - (100 / (Y[i]) * Y_pred[i]))\n",
    "        table.append([Y[i], Y_pred[i]])\n",
    "        if Y[i] == 1:\n",
    "            if Y_pred[i] >= 0.5:\n",
    "                correct += 1\n",
    "        else:\n",
    "            if Y_pred[i] < 0.5:\n",
    "                correct += 1\n",
    "    \n",
    "    print(tabulate(table, headers = ['Real','Prediction'], tablefmt = \"grid\", numalign = \"center\"))\n",
    "    print(\"Cost function: \", j(Y, Y_pred))\n",
    "    print(\"Accuracy: \", 100 * correct / len(Y), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08d1c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = extract_lines('./../SPAM_Corpus/SMS_Spam_Corpus_big.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "833471fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb277ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_lines = tokenize_lines_by_words(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "715d4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_alphabetic_lines = clean_alphabetic_text_lines(tokenized_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "570a123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_lines = remove_stop_words(clean_alphabetic_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96b52517",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_X_y(clean_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20a9cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = transform_tag(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f2ffd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lemmatized = lemmatize_X(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6691f3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = get_vocabulary(X_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15dcf2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_X = get_matrix_X(X_lemmatized, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5a1e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = separateSet(matrix_X.T, Y, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dfecd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = initialize_w(len(vocabulary) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02d7ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fe19ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In iteration 0 the cost function is 0.6931471805599453\n",
      "In iteration 50 the cost function is 0.5387180930449847\n",
      "In iteration 100 the cost function is 0.5231565100205668\n",
      "In iteration 150 the cost function is 0.5089335976861077\n",
      "In iteration 200 the cost function is 0.4958051414510068\n",
      "In iteration 250 the cost function is 0.48360163581010013\n",
      "In iteration 300 the cost function is 0.47219861447814193\n",
      "In iteration 350 the cost function is 0.4615003525277613\n",
      "In iteration 400 the cost function is 0.45143044496591755\n",
      "In iteration 450 the cost function is 0.44192609391271076\n",
      "In iteration 500 the cost function is 0.4329344889694727\n",
      "In iteration 550 the cost function is 0.4244104187909024\n",
      "In iteration 600 the cost function is 0.4163146344199417\n",
      "In iteration 650 the cost function is 0.4086126877166247\n",
      "In iteration 700 the cost function is 0.40127407990595393\n",
      "In iteration 750 the cost function is 0.3942716188975632\n",
      "In iteration 800 the cost function is 0.38758092136235944\n",
      "In iteration 850 the cost function is 0.38118001804340923\n",
      "In iteration 900 the cost function is 0.37504903466485856\n",
      "In iteration 950 the cost function is 0.36916992957757877\n"
     ]
    }
   ],
   "source": [
    "w_train = train(X_train, Y_train, w, alpha, iterations = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8165decd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.80658282, -0.21856362,  1.42935065, ...,  0.        ,\n",
       "       -0.09011692, -3.37857851])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "131371ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|  Real  |  Prediction  |\n",
      "+========+==============+\n",
      "|   0    |   0.241683   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.524152   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.511763   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.251034   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.263388   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.272534   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.626452   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.518023   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.217162   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.24453    |\n",
      "+--------+--------------+\n",
      "|   1    |   0.276287   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.27466    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.144501   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.357826   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.18291    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.230597   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.271571   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.112411   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.228996   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.209185   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.191448   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.236136   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.170159   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.015507   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.263461   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.476891   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.258068   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.255672   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0681443   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.105846   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.305748   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.14226    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.178752   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.192858   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.312994   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.176982   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.240307   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.200523   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.429572   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.13973    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.20697    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.197055   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.250712   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.291793   |\n",
      "+--------+--------------+\n",
      "|   1    |    0.3842    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.143916   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.24726    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.227771   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.31856    |\n",
      "+--------+--------------+\n",
      "|   1    |   0.418817   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.208777   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.469884   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.418767   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.034817   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.198217   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.222765   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.237389   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.128323   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.421387   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.210314   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.183301   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.171374   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0821023   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.236705   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.256507   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.469549   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.17707    |\n",
      "+--------+--------------+\n",
      "|   1    |   0.402282   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0564271   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.398632   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0923375   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.081742   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.240653   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.362325   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.350452   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.216445   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.239625   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.153661   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.151831   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.255931   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.199134   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.412619   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.859485   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.173396   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.251776   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.233878   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.13898    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.266764   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.275327   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.217237   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.465804   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0757389   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.292737   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.210587   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.349965   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.175955   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.19794    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.161231   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.423803   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.015507   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.191179   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.221316   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.561858   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0186773   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.436763   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.242933   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.161733   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.263655   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.204858   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.825462   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.370484   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.473325   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.224259   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.308619   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.089553   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.366296   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.111702   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.243386   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0825423   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.226644   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.47158    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.175435   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.422405   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.422293   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.263476   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.120024   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.108567   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.353736   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.290293   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.212303   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0671083   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.27683    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.140638   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.161823   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.185214   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.269139   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.244278   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.354186   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.23811    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.177717   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.418866   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.451769   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.172321   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.253182   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.476634   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.099999   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.221402   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.258487   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.110113   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0501474   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.279626   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.439675   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.169509   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.23236    |\n",
      "+--------+--------------+\n",
      "|   1    |   0.346694   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.137668   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.318268   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.186882   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.116829   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0905418   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.245551   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.216854   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.298356   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.246814   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.274374   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.206405   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.267663   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.364182   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.115649   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.461165   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0532502   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.109755   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.172741   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.237178   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.450566   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.362772   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.419196   |\n",
      "+--------+--------------+\n",
      "|   0    |    0.2545    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.202097   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.21564    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.169509   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.304522   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.168325   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.56054    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.108185   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.374144   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.249272   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.302596   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.224765   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.540944   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.111634   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.462766   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.549617   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.144381   |\n",
      "+--------+--------------+\n",
      "|   0    |    0.165     |\n",
      "+--------+--------------+\n",
      "|   0    |   0.16445    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.228982   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.161007   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.257582   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.242893   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.195672   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.536583   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.491115   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.146572   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.162163   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.139533   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0766018   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.439859   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.27331    |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0905245   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.427004   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.305244   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.199893   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.506007   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.483441   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.242497   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.443725   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.170327   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.228231   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.187335   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.418231   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.120947   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.439618   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.202971   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.289004   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.170339   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.217196   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.112094   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.308619   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.107393   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.203001   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.547844   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.498316   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.015507   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.187134   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.249456   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.537253   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.153767   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.12146    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.265961   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.215679   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.269732   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.653416   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.11601    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.161169   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.182218   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.199058   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.178994   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.265788   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.176112   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.293262   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.24151    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.275703   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.166902   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.110751   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.42983    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.350975   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.115649   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.303318   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.220852   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.266233   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.163149   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.34618    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.274553   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.38584    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.141403   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.223331   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.309166   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.207879   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.131108   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.474947   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.171391   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.206653   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.138282   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.256698   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0413931   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.281713   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.601289   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.298045   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.477944   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.233119   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0753276   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.165441   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.170869   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.164937   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0445713   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.472218   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.469079   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.124059   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.348064   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.149444   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.122981   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.268131   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.259524   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.261549   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.157157   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.222348   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.460302   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.173151   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.146476   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.310921   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.294206   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.190026   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.137544   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.525984   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.341191   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.26303    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.25368    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.19471    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.195732   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.237919   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.263334   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.139056   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.175667   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.42983    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.182653   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.243586   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.059823   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.476891   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.286946   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.161919   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.41718    |\n",
      "+--------+--------------+\n",
      "|   1    |   0.397594   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.41233    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.19652    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.218022   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.299162   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.601289   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.296291   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.158576   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.410836   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.245224   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.15701    |\n",
      "+--------+--------------+\n",
      "|   1    |   0.318268   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.210875   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.125828   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.242315   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.362325   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.142643   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0715997   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.226214   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0898615   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.226752   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.136982   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.224316   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.203299   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.160793   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.159337   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.185616   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.496953   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0956282   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.566189   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.174226   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.117195   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.159713   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0827814   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.628039   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.22267    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.223716   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.277608   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.394849   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.244064   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0352356   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.247056   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.120629   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.139033   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.107028   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.272678   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.455839   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.322914   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.225606   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.189089   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.431688   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.160911   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.106738   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0768564   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.200135   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.312358   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.38584    |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0732819   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.147261   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.209727   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.198247   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.105272   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.420386   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.232233   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.184184   |\n",
      "+--------+--------------+\n",
      "|   1    |   0.363448   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.165269   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.21378    |\n",
      "+--------+--------------+\n",
      "|   1    |   0.483559   |\n",
      "+--------+--------------+\n",
      "|   0    |  0.0855729   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.28675    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.29655    |\n",
      "+--------+--------------+\n",
      "|   0    |   0.209944   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.015507   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.212727   |\n",
      "+--------+--------------+\n",
      "|   0    |   0.151828   |\n",
      "+--------+--------------+\n",
      "Cost function:  0.3657632100204017\n",
      "Accuracy:  81.15577889447236 %\n"
     ]
    }
   ],
   "source": [
    "test(X_test, Y_test, w_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
